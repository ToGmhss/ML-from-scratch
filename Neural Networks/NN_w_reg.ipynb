{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b07ff04",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b598980",
   "metadata": {},
   "source": [
    "### all necessary packages are listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dfb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# keras and regularization\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c92a86",
   "metadata": {},
   "source": [
    "### the functions defined below are the main coding parts of the Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b47e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with two units and one drop_out rate as hyperparamters\n",
    "def baseline(un1, un2, dr):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(units=un1, activation=\"relu\", input_shape=(X_train.shape[-1],) ),\n",
    "            # randomly delete 30% of the input units below\n",
    "            keras.layers.Dropout(dr),\n",
    "            keras.layers.Dense(units=un2, activation=\"relu\"),\n",
    "            # the output layer, with a single neuron\n",
    "            keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    learning_rate = 0.001\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC()\n",
    "             )\n",
    "    # training result\n",
    "    y_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_train, y_pred, average='macro')[:-1]\n",
    "    print(\"training result: \", result, roc_auc_score(y_train, y_pred))\n",
    "    \n",
    "    # testing result\n",
    "    #y_pred = model.predict(X_test)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_test, y_pred, average='macro')[:-1]\n",
    "    print(\"testing result:  \", result, roc_auc_score(y_test, y_pred))\n",
    "print(\"precision, recall, f1-score, auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with one more layer\n",
    "# ann is short for artificial neural network\n",
    "def ann(un1, un2, un3, dr):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(units=un1, activation=\"relu\", input_shape=(X_train.shape[-1],) ),\n",
    "            # randomly delete 30% of the input units below\n",
    "            keras.layers.Dropout(dr),\n",
    "            keras.layers.Dense(units=un2, activation=\"relu\"),\n",
    "            keras.layers.Dense(units=un3, activation=\"relu\"),\n",
    "            # the output layer, with a single neuron\n",
    "            keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    learning_rate = 0.001\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC()\n",
    "             )\n",
    "    # training result\n",
    "    y_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_train, y_pred, average='macro')[:-1]\n",
    "    print(\"training result: \", result, roc_auc_score(y_train, y_pred))\n",
    "    \n",
    "    # testing result\n",
    "    #y_pred = model.predict(X_test)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_test, y_pred, average='macro')[:-1]\n",
    "    print(\"testing result:  \", result, roc_auc_score(y_test, y_pred))\n",
    "print(\"precision, recall, f1-score, auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1\n",
    "# baseline model with L1 regularization added\n",
    "def reg1(un1, un2, dr):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(units=un1, activation=\"relu\", input_shape=(X_train.shape[-1],) ),\n",
    "            # randomly delete 30% of the input units below\n",
    "            keras.layers.Dropout(dr),\n",
    "            keras.layers.Dense(units=un2, activation=\"relu\", kernel_regularizer='l1'),\n",
    "            # the output layer, with a single neuron\n",
    "            keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    learning_rate = 0.001\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC()\n",
    "                 )\n",
    "    # training result\n",
    "    y_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_train, y_pred, average='macro')[:-1]\n",
    "    print(\"training result: \", result, roc_auc_score(y_train, y_pred))\n",
    "    \n",
    "    # testing result\n",
    "    #y_pred = model.predict(X_test)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_test, y_pred, average='macro')[:-1]\n",
    "    print(\"testing result:  \", result, roc_auc_score(y_test, y_pred))\n",
    "print(\"precision, recall, f1-score, auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2940f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2\n",
    "# baseline model with L2 regularization addedï¼Œlam is short for lambda, which can be tuned\n",
    "def reg2(un1, un2, dr, lam):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(units=un1, activation=\"relu\", input_shape=(X_train.shape[-1],) ),\n",
    "            # randomly delete 30% of the input units below\n",
    "            keras.layers.Dropout(dr),\n",
    "            keras.layers.Dense(units=un2, activation=\"relu\", \n",
    "                              bias_regularizer=regularizers.l2(lam),\n",
    "                            activity_regularizer=regularizers.l2(lam)),\n",
    "            # the output layer, with a single neuron\n",
    "            keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    learning_rate = 0.001\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC()\n",
    "             )\n",
    "    # training result\n",
    "    y_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_train, y_pred, average='macro')[:-1]\n",
    "    print(\"training result: \", result, roc_auc_score(y_train, y_pred))\n",
    "    \n",
    "    # testing result\n",
    "    #y_pred = model.predict(X_test)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    result = precision_recall_fscore_support(y_test, y_pred, average='macro')[:-1]\n",
    "    print(\"testing result:  \", result, roc_auc_score(y_test, y_pred))\n",
    "print(\"precision, recall, f1-score, auc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
